{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5cFq_TgWlQ_"
   },
   "source": [
    "# Homework 7 - Network Compression (Network Pruning)\n",
    "\n",
    "网络压缩 - Neural Network Compression。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNiZCGrIYKdR"
   },
   "source": [
    "# Readme\n",
    "\n",
    "Compression有很多方法，作业7实现其中的四种，分別是:\n",
    "\n",
    "* 知识蒸馏 Knowledge Distillation\n",
    "* 网络剪枝 Network Pruning\n",
    "* 结构设计 Architecture Design\n",
    "* 参数量话 Weight Quantization\n",
    "\n",
    "这个notebook介紹Network Pruning，\n",
    "本实验提供一个已经做完Knowledge Distillation的小model來做Pruning。\n",
    "（即“student_custom_small.bin”文件）\n",
    "\n",
    "* Model结构 / Architecute Design在同目录的hw7_Architecture_Design.ipynb。\n",
    "* 下载已經train好的小model(0.99M): https://drive.google.com/open?id=12wtIa0WVRcpboQzhgRUJOpcXe23tgWUL\n",
    "  * 参数为 base=16, width_mult=1 (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "XdzskhdEb65Z",
    "outputId": "7c855984-444f-4a53-86f7-1e233ccdd9b1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "# 加载模型结构(在hw7_Architecture_Design.ipynb內)\n",
    "%run \"hw7_Architecture_Design.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bdUtCxBBcH0B"
   },
   "source": [
    "Network Pruning\n",
    "===\n",
    "在這裡我們會教Neuron Pruning。\n",
    "<img src=\"https://i.imgur.com/Iwp90Wp.png\" width=\"500px\">\n",
    "\n",
    "簡單上來說就是讓一個已經學完的model中的neuron進行刪減，讓整個網路變得更瘦。\n",
    "\n",
    "## Weight & Neuron Pruning\n",
    "* weight和neuron pruning差別在於prune掉一個neuron就等於是把一個matrix的整個column全部砍掉。但如此一來速度就會比較快。因為neuron pruning後matrix整體變小，但weight pruning大小不變，只是有很多空洞。\n",
    "\n",
    "## What to Prune?\n",
    "* 既然要Neuron Pruning，那就必須要先衡量Neuron的重要性。衡量完所有的Neuron後，就可以把比較不重要的Neuron刪減掉。\n",
    "* 在這裡我們介紹一個很簡單可以衡量Neuron重要性的方法 - 就是看batchnorm layer的$\\gamma$因子來決定neuron的重要性。 (by paper - Network Slimming)\n",
    "  ![](https://i.imgur.com/JVpCm2r.png)\n",
    "* 相信大家看這個pytorch提供的batchnorm公式應該就可以意識到為甚麼$\\gamma$可以當作重要性來衡量了:)\n",
    "\n",
    "* Network Slimming其實步驟沒有這麼簡單，有興趣的同學可以check以下連結。[Network Slimming](https://arxiv.org/abs/1708.06519)\n",
    "\n",
    "\n",
    "## 為甚麼這會 work?\n",
    "* 樹多必有枯枝，有些neuron只是在躺分，所以有他沒他沒有差。\n",
    "* 困難的說可以回想起老師說過的大樂透假說(The Lottery Ticket Hypothesis)就可以知道了。\n",
    "\n",
    "## 要怎麼實作?\n",
    "* 為了避免複雜的操作，我們會將StudentNet(width_mult=$\\alpha$)的neuron經過篩選後移植到StudentNet(width_mult=$\\beta$)。($\\alpha > \\beta$)\n",
    "* 篩選的方法也很簡單，只需要抓出每一個block的batchnorm的$\\gamma$即可。\n",
    "\n",
    "## 一些實作細節\n",
    "* 假設model中間兩層是這樣的:\n",
    "\n",
    "|Layer|Output # of Channels|\n",
    "|-|-|\n",
    "|Input|in_chs|\n",
    "|Depthwise(in_chs)|in_chs|\n",
    "|BatchNorm(in_chs)|in_chs|\n",
    "|Pointwise(in_chs, **mid_chs**)|**mid_chs**|\n",
    "|**Depthwise(mid_chs)**|**mid_chs**|\n",
    "|**BatchNorm(mid_chs)**|**mid_chs**|\n",
    "|Pointwise(**mid_chs**, out_chs)|out_chs|\n",
    "\n",
    "則你會發現利用第二個BatchNorm來做篩選的時候，跟他的Neuron有直接關係的是該層的Depthwise&Pointwise以及上層的Pointwise。\n",
    "因此再做neuron篩選時記得要將這四個(包括自己, bn)也要同時prune掉。\n",
    "\n",
    "* 在Design Architecure內，model的一個block，名稱所對應的Weight；\n",
    "\n",
    "|#|name|meaning|code|weight shape|\n",
    "|-|-|-|-|-|\n",
    "|0|cnn.{i}.0|Depthwise Convolution Layer|nn.Conv2d(x, x, 3, 1, 1, group=x)|(x, 1, 3, 3)|\n",
    "|1|cnn.{i}.1|Batch Normalization|nn.BatchNorm2d(x)|(x)|\n",
    "|2||ReLU6|nn.ReLU6||\n",
    "|3|cnn.{i}.3|Pointwise Convolution Layer|nn.Conv2d(x, y, 1),|(y, x, 1, 1)|\n",
    "|4||MaxPooling|nn.MaxPool2d(2, 2, 0)||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-dSi_P-4les"
   },
   "outputs": [],
   "source": [
    "def network_slimming(old_model, new_model):\n",
    "    params = old_model.state_dict()\n",
    "    new_params = new_model.state_dict()\n",
    "    \n",
    "    # selected_idx: 每一層所選擇的neuron index\n",
    "    selected_idx = []\n",
    "    # 我們總共有7層CNN，因此逐一抓取選擇的neuron index們。\n",
    "    for i in range(8):\n",
    "        # 根據上表，我們要抓的gamma係數在cnn.{i}.1.weight內。\n",
    "        importance = params[f'cnn.{i}.1.weight']\n",
    "        # 抓取總共要篩選幾個neuron。\n",
    "        old_dim = len(importance)\n",
    "        new_dim = len(new_params[f'cnn.{i}.1.weight'])\n",
    "        # 以Ranking做Index排序，較大的會在前面(descending=True)。\n",
    "        ranking = torch.argsort(importance, descending=True)\n",
    "        # 把篩選結果放入selected_idx中。\n",
    "        selected_idx.append(ranking[:new_dim])\n",
    "\n",
    "    now_processed = 1\n",
    "    for (name, p1), (name2, p2) in zip(params.items(), new_params.items()):\n",
    "        # 如果是cnn層，則移植參數。\n",
    "        # 如果是FC層，或是該參數只有一個數字(例如batchnorm的tracenum等等資訊)，那麼就直接複製。\n",
    "        if name.startswith('cnn') and p1.size() != torch.Size([]) and now_processed != len(selected_idx):\n",
    "            # 當處理到Pointwise的weight時，讓now_processed+1，表示該層的移植已經完成。\n",
    "            if name.startswith(f'cnn.{now_processed}.3'):\n",
    "                now_processed += 1\n",
    "\n",
    "            # 如果是pointwise，weight會被上一層的pruning和下一層的pruning所影響，因此需要特判。\n",
    "            if name.endswith('3.weight'):\n",
    "                # 如果是最後一層cnn，則輸出的neuron不需要prune掉。\n",
    "                if len(selected_idx) == now_processed:\n",
    "                    new_params[name] = p1[:,selected_idx[now_processed-1]]\n",
    "                # 反之，就依照上層和下層所選擇的index進行移植。\n",
    "                # 這裡需要注意的是Conv2d(x,y,1)的weight shape是(y,x,1,1)，順序是反的。\n",
    "                else:\n",
    "                    new_params[name] = p1[selected_idx[now_processed]][:,selected_idx[now_processed-1]]\n",
    "            else:\n",
    "                new_params[name] = p1[selected_idx[now_processed]]\n",
    "        else:\n",
    "            new_params[name] = p1\n",
    "\n",
    "    # 讓新model load進被我們篩選過的parameters，並回傳new_model。        \n",
    "    new_model.load_state_dict(new_params)\n",
    "    return new_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NfnRoOt5VIze"
   },
   "source": [
    "# Data Processing\n",
    "\n",
    "我們的Dataset使用的是跟Hw3 - CNN同樣的Dataset，因此這個區塊的Augmentation / Read Image大家參考就好。\n",
    "\n",
    "如果有不會的話可以回去看Hw3的colab。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExdUvTRaVNOT"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, folderName, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.label = []\n",
    "\n",
    "        for img_path in glob(folderName + '/*.jpg'):\n",
    "            try:\n",
    "                # Get classIdx by parsing image path\n",
    "                class_idx = int(re.findall(re.compile(r'\\d+'), img_path)[1])\n",
    "            except:\n",
    "                # if inference mode (there's no answer), class_idx default 0\n",
    "                class_idx = 0\n",
    " \n",
    "            image = Image.open(img_path)\n",
    "            # Get File Descriptor\n",
    "            image_fp = image.fp\n",
    "            image.load()\n",
    "            # Close File Descriptor (or it'll reach OPEN_MAX)\n",
    "            image_fp.close()\n",
    "\n",
    "            self.data.append(image)\n",
    "            self.label.append(class_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        image = self.data[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.label[idx]\n",
    "\n",
    "\n",
    "trainTransform = transforms.Compose([\n",
    "    transforms.RandomCrop(256, pad_if_needed=True, padding_mode='symmetric'),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "testTransform = transforms.Compose([\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def get_dataloader(mode='training', batch_size=32):\n",
    "\n",
    "    assert mode in ['training', 'evaluation', 'validation']\n",
    "\n",
    "    dataset = MyDataset(\n",
    "        f'./food-11/{mode}',\n",
    "        transform=trainTransform if mode == 'training' else testTransform)\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(mode == 'training'))\n",
    "\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ACPwL9_JWceQ"
   },
   "source": [
    "# Pre-processing\n",
    "\n",
    "我們已經提供原始小model binary，架構是hw7_Architecture_Design.ipynb中的StudentNet。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wzuuGvnbWkG8"
   },
   "outputs": [],
   "source": [
    "# get dataloader\n",
    "train_dataloader = get_dataloader('training', batch_size=32)\n",
    "valid_dataloader = get_dataloader('validation', batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "ZWdQtDtgoGCp",
    "outputId": "754a2fb7-b571-4b46-fceb-7acc98f0744a"
   },
   "outputs": [],
   "source": [
    "net = StudentNet().cuda()\n",
    "net.load_state_dict(torch.load('student_custom_small.bin'))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wvc1W5yO2QaE"
   },
   "source": [
    "# Start Training\n",
    "\n",
    "* 每次Prune rate是0.95，Prune完後會重新fine-tune 3 epochs。\n",
    "* 其餘的步驟與你在做Hw3 - CNN的時候一樣。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-TzmWtT62Qmy",
    "outputId": "28d3f0e3-1863-4dcb-a3f2-b2a86566906d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rate 0.9500 epoch   0: train loss: 0.4974, acc 0.8645 valid loss: 1.1000, acc 0.7994\n",
      "rate 0.9500 epoch   1: train loss: 0.4943, acc 0.8683 valid loss: 1.0939, acc 0.7991\n",
      "rate 0.9500 epoch   2: train loss: 0.4909, acc 0.8674 valid loss: 1.1147, acc 0.7985\n",
      "rate 0.9500 epoch   3: train loss: 0.5016, acc 0.8650 valid loss: 1.1116, acc 0.7965\n",
      "rate 0.9500 epoch   4: train loss: 0.5025, acc 0.8662 valid loss: 1.1313, acc 0.7953\n",
      "rate 0.9025 epoch   0: train loss: 0.6101, acc 0.8389 valid loss: 1.1591, acc 0.7822\n",
      "rate 0.9025 epoch   1: train loss: 0.5899, acc 0.8397 valid loss: 1.1767, acc 0.7787\n",
      "rate 0.9025 epoch   2: train loss: 0.5823, acc 0.8394 valid loss: 1.1560, acc 0.7848\n",
      "rate 0.9025 epoch   3: train loss: 0.6059, acc 0.8383 valid loss: 1.1847, acc 0.7840\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b05946d801a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mvalid_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-b05946d801a4>\u001b[0m in \u001b[0;36mrun_epoch\u001b[1;34m(dataloader, update, alpha)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtotal_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_hit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mnow_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;31m# 清空 optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg_fmt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg_fmt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_epoch(dataloader, update=True, alpha=0.5):\n",
    "    total_num, total_hit, total_loss = 0, 0, 0\n",
    "    for now_step, batch_data in enumerate(dataloader):\n",
    "        # 清空 optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # 處理 input\n",
    "        inputs, labels = batch_data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "  \n",
    "        logits = net(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        if update:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_hit += torch.sum(torch.argmax(logits, dim=1) == labels).item()\n",
    "        total_num += len(inputs)\n",
    "        total_loss += loss.item() * len(inputs)\n",
    "\n",
    "    return total_loss / total_num, total_hit / total_num\n",
    "\n",
    "now_width_mult = 1\n",
    "for i in range(5):\n",
    "    now_width_mult *= 0.95\n",
    "    new_net = StudentNet(width_mult=now_width_mult).cuda()\n",
    "    params = net.state_dict()\n",
    "    net = network_slimming(net, new_net)\n",
    "    now_best_acc = 0\n",
    "    for epoch in range(5):\n",
    "        net.train()\n",
    "        train_loss, train_acc = run_epoch(train_dataloader, update=True)\n",
    "        net.eval()\n",
    "        valid_loss, valid_acc = run_epoch(valid_dataloader, update=False)\n",
    "        # 在每個width_mult的情況下，存下最好的model。\n",
    "        if valid_acc > now_best_acc:\n",
    "            now_best_acc = valid_acc\n",
    "            torch.save(net.state_dict(), f'custom_small_rate_{now_width_mult}.bin')\n",
    "        print('rate {:6.4f} epoch {:>3d}: train loss: {:6.4f}, acc {:6.4f} valid loss: {:6.4f}, acc {:6.4f}'.format(now_width_mult, \n",
    "            epoch, train_loss, train_acc, valid_loss, valid_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JFu_opsbl3sS"
   },
   "source": [
    "# Inference\n",
    "\n",
    "同Hw3，請參考該作業:)。"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "hw7_Network_Pruning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
